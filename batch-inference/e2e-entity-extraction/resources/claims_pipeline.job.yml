# Lakeflow Job Definitions for Claims Extraction Pipeline

resources:
  jobs:
    # Main pipeline: Ingest + Extract
    claims_extraction_pipeline:
      name: claims-extraction-pipeline
      description: "End-to-end medical claims extraction pipeline"
      max_concurrent_runs: 1
      queue:
        enabled: true

      tasks:
        # Task 1: Ingest and parse documents
        - task_key: ingest_documents
          description: "Parse PDFs from volume using ai_parse_document"
          notebook_task:
            notebook_path: ../src/pipeline/01_ingest.py
            source: WORKSPACE
          timeout_seconds: 3600

        # Task 2: Classify and extract
        - task_key: classify_extract
          description: "Call agent endpoint for classification and extraction"
          depends_on:
            - task_key: ingest_documents
          notebook_task:
            notebook_path: ../src/pipeline/02_extract.py
            source: WORKSPACE
          timeout_seconds: 7200

    # Separate job: Deploy the agent
    deploy_agent:
      name: claims-extraction-agent-deploy
      description: "Deploy the claims extraction agent to Model Serving"
      max_concurrent_runs: 1

      tasks:
        - task_key: deploy
          description: "Log and deploy the PyFunc agent"
          notebook_task:
            notebook_path: ../src/setup/deploy_agent.py
            source: WORKSPACE
          timeout_seconds: 3600

    # Separate job: Evaluation (run manually)
    evaluation:
      name: claims-extraction-evaluation
      description: "Run MLflow evaluation on the extraction agent"
      max_concurrent_runs: 1

      tasks:
        - task_key: evaluate
          description: "Evaluate model and log metrics"
          notebook_task:
            notebook_path: ../src/monitoring/evaluate.py
            source: WORKSPACE
          timeout_seconds: 3600
